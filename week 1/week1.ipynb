{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressWarnings(suppressMessages(library(\"kernlab\")))\n",
    "suppressWarnings(suppressMessages(library(\"caret\")))\n",
    "suppressWarnings(suppressMessages(library(kknn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data <- read.table(\"./credit_card_data.txt\", header = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_list <- c(0.00001, 0.001, 0.01, 0.1, 1, 3, 5, 10, 15, 20, 100, 1000, 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- For C =  1e-05  -----\n",
      " Setting default kernel parameters  \n",
      "\n",
      "Accuracy:  54.74006 %\n",
      "Precision:  0.5474006\n",
      "Recall:  1\n",
      "F1 score:  0.7075099\n",
      "----- For C =  0.001  -----\n",
      " Setting default kernel parameters  \n",
      "\n",
      "Accuracy:  83.79205 %\n",
      "Precision:  0.8088235\n",
      "Recall:  0.9217877\n",
      "F1 score:  0.8616188\n",
      "----- For C =  0.01  -----\n",
      " Setting default kernel parameters  \n",
      "\n",
      "Accuracy:  86.39144 %\n",
      "Precision:  0.9438944\n",
      "Recall:  0.7988827\n",
      "F1 score:  0.8653555\n",
      "----- For C =  0.1  -----\n",
      " Setting default kernel parameters  \n",
      "\n",
      "Accuracy:  86.39144 %\n",
      "Precision:  0.9438944\n",
      "Recall:  0.7988827\n",
      "F1 score:  0.8653555\n",
      "----- For C =  1  -----\n",
      " Setting default kernel parameters  \n",
      "\n",
      "Accuracy:  86.39144 %\n",
      "Precision:  0.9438944\n",
      "Recall:  0.7988827\n",
      "F1 score:  0.8653555\n",
      "----- For C =  3  -----\n",
      " Setting default kernel parameters  \n",
      "\n",
      "Accuracy:  86.39144 %\n",
      "Precision:  0.9438944\n",
      "Recall:  0.7988827\n",
      "F1 score:  0.8653555\n",
      "----- For C =  5  -----\n",
      " Setting default kernel parameters  \n",
      "\n",
      "Accuracy:  86.39144 %\n",
      "Precision:  0.9438944\n",
      "Recall:  0.7988827\n",
      "F1 score:  0.8653555\n",
      "----- For C =  10  -----\n",
      " Setting default kernel parameters  \n",
      "\n",
      "Accuracy:  86.39144 %\n",
      "Precision:  0.9438944\n",
      "Recall:  0.7988827\n",
      "F1 score:  0.8653555\n",
      "----- For C =  15  -----\n",
      " Setting default kernel parameters  \n",
      "\n",
      "Accuracy:  86.39144 %\n",
      "Precision:  0.9438944\n",
      "Recall:  0.7988827\n",
      "F1 score:  0.8653555\n",
      "----- For C =  20  -----\n",
      " Setting default kernel parameters  \n",
      "\n",
      "Accuracy:  86.39144 %\n",
      "Precision:  0.9438944\n",
      "Recall:  0.7988827\n",
      "F1 score:  0.8653555\n",
      "----- For C =  100  -----\n",
      " Setting default kernel parameters  \n",
      "\n",
      "Accuracy:  86.39144 %\n",
      "Precision:  0.9438944\n",
      "Recall:  0.7988827\n",
      "F1 score:  0.8653555\n",
      "----- For C =  1000  -----\n",
      " Setting default kernel parameters  \n",
      "\n",
      "Accuracy:  86.23853 %\n",
      "Precision:  0.9407895\n",
      "Recall:  0.7988827\n",
      "F1 score:  0.8640483\n",
      "----- For C =  1e+06  -----\n",
      " Setting default kernel parameters  \n",
      "\n",
      "Accuracy:  62.53823 %\n",
      "Precision:  0.6637681\n",
      "Recall:  0.6396648\n",
      "F1 score:  0.6514936"
     ]
    }
   ],
   "source": [
    "for (c in c_list){\n",
    "    cat(\"\\n----- For C = \", c, \" -----\\n\")\n",
    "    model <- ksvm(as.matrix(data[, 1:10]),as.factor(data[, 11]),type=\"C-svc\",kernel=\"vanilladot\",C=c,scaled=TRUE)\n",
    "    prediction <- predict(model, as.matrix(data[, 1:10]))\n",
    "    result <- confusionMatrix(prediction, as.factor(data[, 11]))\n",
    "    accuracy <- result$overall[\"Accuracy\"]*100\n",
    "    precision <- result$byClass['Pos Pred Value']\n",
    "    recall <- result$byClass['Sensitivity']\n",
    "    cat(\"\\nAccuracy: \", accuracy, \"%\")\n",
    "    cat(\"\\nPrecision: \", precision)\n",
    "    cat(\"\\nRecall: \", recall)\n",
    "    f_measure <- 2 * ((precision * recall) / (precision + recall))\n",
    "    cat(\"\\nF1 score: \", f_measure)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "Accuracy decreases for extremely low and higher values of C. \n",
    "<br>C = 1e-05 ----> Accuracy = 54.74%\n",
    "<br>C = 1e+06 ----> Accuracy = 62.54%\n",
    "\n",
    "<br>It is interesting to note that the metrics accuracy, precision, recall remain same for all values tested between 0.01 and 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting default kernel parameters  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>V1</dt>\n",
       "\t\t<dd>-0.00100653481057611</dd>\n",
       "\t<dt>V2</dt>\n",
       "\t\t<dd>-0.00117290480611665</dd>\n",
       "\t<dt>V3</dt>\n",
       "\t\t<dd>-0.00162619672236963</dd>\n",
       "\t<dt>V4</dt>\n",
       "\t\t<dd>0.0030064202649194</dd>\n",
       "\t<dt>V5</dt>\n",
       "\t\t<dd>1.00494056410556</dd>\n",
       "\t<dt>V6</dt>\n",
       "\t\t<dd>-0.00282594323043472</dd>\n",
       "\t<dt>V7</dt>\n",
       "\t\t<dd>0.000260029507016313</dd>\n",
       "\t<dt>V8</dt>\n",
       "\t\t<dd>-0.000534955143494997</dd>\n",
       "\t<dt>V9</dt>\n",
       "\t\t<dd>-0.00122837582291523</dd>\n",
       "\t<dt>V10</dt>\n",
       "\t\t<dd>0.106363399527188</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[V1] -0.00100653481057611\n",
       "\\item[V2] -0.00117290480611665\n",
       "\\item[V3] -0.00162619672236963\n",
       "\\item[V4] 0.0030064202649194\n",
       "\\item[V5] 1.00494056410556\n",
       "\\item[V6] -0.00282594323043472\n",
       "\\item[V7] 0.000260029507016313\n",
       "\\item[V8] -0.000534955143494997\n",
       "\\item[V9] -0.00122837582291523\n",
       "\\item[V10] 0.106363399527188\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "V1\n",
       ":   -0.00100653481057611V2\n",
       ":   -0.00117290480611665V3\n",
       ":   -0.00162619672236963V4\n",
       ":   0.0030064202649194V5\n",
       ":   1.00494056410556V6\n",
       ":   -0.00282594323043472V7\n",
       ":   0.000260029507016313V8\n",
       ":   -0.000534955143494997V9\n",
       ":   -0.00122837582291523V10\n",
       ":   0.106363399527188\n",
       "\n"
      ],
      "text/plain": [
       "           V1            V2            V3            V4            V5 \n",
       "-0.0010065348 -0.0011729048 -0.0016261967  0.0030064203  1.0049405641 \n",
       "           V6            V7            V8            V9           V10 \n",
       "-0.0028259432  0.0002600295 -0.0005349551 -0.0012283758  0.1063633995 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.081584921659538"
      ],
      "text/latex": [
       "0.081584921659538"
      ],
      "text/markdown": [
       "0.081584921659538"
      ],
      "text/plain": [
       "[1] 0.08158492"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#picking the default model used in the homework C = 100 to obtain the coefficients.\n",
    "model <- ksvm(as.matrix(data[, 1:10]),as.factor(data[, 11]),type=\"C-svc\",kernel=\"vanilladot\",C=100,scaled=TRUE)\n",
    "\n",
    "# calculate a1...am\n",
    "a <- colSums(model@xmatrix[[1]] * model@coef[[1]]) \n",
    "a\n",
    "# calculate a0\n",
    "a0 <- -model@b\n",
    "a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.954128440366973"
      ],
      "text/latex": [
       "0.954128440366973"
      ],
      "text/markdown": [
       "0.954128440366973"
      ],
      "text/plain": [
       "[1] 0.9541284"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#trying different kernel. Someone mentioned on the slack channel rbfdot kernel gets almost 100% accuracy. So lets try\n",
    "model <- ksvm(as.matrix(data[, 1:10]),as.factor(data[, 11]),type=\"C-svc\",kernel=\"rbfdot\",C=100,scaled=TRUE)\n",
    "pred <- predict(model,data[,1:10])\n",
    "sum(pred == data[,11]) / nrow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that 95% accuracy is achieved. However, this is a clear case of overfitting where the classifier performs well on the training data (data which the classifier has seen or rather data used to train the classifier) but will yield poor performance on data which it has not seen. Hence, we will get poor generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data$V11 <- as.factor(data$V11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " For K =  1 accuracy =  0.8149847 \n",
      "\n",
      " For K =  2 accuracy =  0.8149847 \n",
      "\n",
      " For K =  3 accuracy =  0.82263 \n",
      "\n",
      " For K =  4 accuracy =  0.82263 \n",
      "\n",
      " For K =  5 accuracy =  0.8455657 \n",
      "\n",
      " For K =  6 accuracy =  0.8455657 \n",
      "\n",
      " For K =  7 accuracy =  0.8470948 \n",
      "\n",
      " For K =  8 accuracy =  0.8470948 \n",
      "\n",
      " For K =  9 accuracy =  0.8318043 \n",
      "\n",
      " For K =  10 accuracy =  0.8318043 \n",
      "\n",
      " For K =  11 accuracy =  0.8348624 \n",
      "\n",
      " For K =  12 accuracy =  0.8348624 \n",
      "\n",
      " For K =  13 accuracy =  0.8302752 \n",
      "\n",
      " For K =  14 accuracy =  0.8302752 \n",
      "\n",
      " For K =  15 accuracy =  0.8256881 \n",
      "\n",
      " For K =  16 accuracy =  0.8256881 \n",
      "\n",
      " For K =  17 accuracy =  0.82263 \n",
      "\n",
      " For K =  18 accuracy =  0.82263 \n",
      "\n",
      " For K =  19 accuracy =  0.82263 \n",
      "\n",
      " For K =  20 accuracy =  0.82263 \n"
     ]
    }
   ],
   "source": [
    "for (k in 1:20){\n",
    "    pred <- c()\n",
    "    for (i in 1:nrow(data)){\n",
    "        knn <- kknn(V11 ~ .,data[-i, ], data[i, ], k = k, distance = 2, kernel = \"rectangular\", scale=TRUE)\n",
    "        pred <- c(pred, knn$fitted.values)\n",
    "    }\n",
    "    pred <- pred-1\n",
    "    accuracy <- sum(pred == data[,11]) / nrow(data)\n",
    "    cat(\"\\n For K = \", k, \"accuracy = \", accuracy, \"\\n\")       \n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
